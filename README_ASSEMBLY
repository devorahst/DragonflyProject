Running the assembler (the first half of the pipeline).

1. Data should be previously trimmed and the user should be in the chase conda environment.

2. In order to launch each job, the directory needs the species names file in the correct format, the reference genome, the probe hits, and the sample sequences.

3. The slurm file/job job is dependent on a python file called “ASS_F4_fast.py” this script requires access to usearch to function. So make sure usearch is in the directory and is executable.

4. The array number for the slurm file will be the same size as the number of species in the species names file. For our test 260 for Odonata and 95 for Ephem.

5. Use "sbatch" followed by the job file to launch the script. Correctly running jobs will produce A LOT of files. The files that are needed end in targetsFULL_ORTHO.fasta and targets_ORTHO.fasta.


